<center>lecture7 RNN</center>

# 回顾

训练前馈神经网络的三个主要阶段，每个阶段都包括了一系列的关键步骤和考虑因素：

1. 一次性设置 (One Time Setup)

- **激活函数**：选择合适的激活函数，如ReLU，以促进非线性学习和避免梯度消失问题。
- **数据预处理**：标准化输入数据，例如图像数据减去均值和除以标准差，以提高模型训练效率和性能。
- **权重初始化**：使用如Xavier或He初始化来适当设置权重，这有助于稳定训练过程。
- **正则化**：应用如Dropout、L1/L2正则化等技术来避免过拟合。
- **梯度检查**：在开始大规模训练之前，验证反向传播的实现是否正确，确保梯度计算无误。

2. 训练动态 (Training Dynamics)

- **监督学习过程**：密切关注训练过程，调整训练参数以响应模型的表现，如调整学习率或更改批次大小。
- **参数更新**：实施有效的参数更新策略，如使用Adam或SGD优化器。
- **超参数优化**：使用网格搜索、随机搜索或贝叶斯优化方法来找到最佳的超参数设置。

3. 评估 (Evaluation)

- **模型集成**：结合多个模型的预测来提高测试性能，通过多样化的模型减少泛化误差。
- **测试时增强**：在测试阶段应用数据增强技术，如旋转或裁剪图像，以提高模型对新数据的鲁棒性。
- **迁移学习**：利用在大型数据集上预训练的模型，通过迁移学习来处理数据量较少的新任务，这通常可以显著提高模型的性能。

# RNN

内部状态：关键思想是RNN拥有一个“内部状态”，该状态在处理序列时不断更新。这个状态充当了网络的记忆，帮助网络捕捉到序列中的时间动态和依赖关系。

RNN隐藏状态更新
$$
h_t = f_W(h_{t-1},x_t)
$$
$h_t$新状态，$f_W$带有参数W的函数，$h_{t-1}$旧状态，$x_t$某个时间步的输入向量

$h_{t-1} $表示上一个时间步的隐藏状态，代表模型的“记忆”。

$x_t$是当前时间步的输入向量，代表当前时刻的输入信息

$f_W$是一个函数，通常是一个线性变换后加上非线性激活函数

$h_t$是当前时间步更新后的隐藏状态

RNN输出门
$$
y_t = f_W{_{hy}}(h_y)
$$
$h_t$表示当前时间步的隐藏状态，$f_W{_{hy}}$是一个函数，依赖于参数$W{_{hy}}$，用于隐藏状态$h_t$映射到输出$y_t$

