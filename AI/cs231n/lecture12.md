<center>lecture12 自监督学习 Self-Supervised Learning</center>

四种计算机视觉任务:

1. 分类 (Classification)
2. 语义分割 (Semantic Segmentation)
   图片被分割成不同颜色的区域，代表不同类别的物体或场景元素，例如草地（绿色）、猫（黄色）、树（粉色）和天空（蓝色）。
3. 目标检测 (Object Detection)
4. 实例分割 (Instance Segmentation)

我们可以做一个简单的例子，来说明子监督学习的流程：

**任务目标**：您希望解决的最终任务是区分猫和狗。

**数据资源**：

- **无标签的图片**：这些图片数量很大，但不一定与猫狗相关，可能包含各种各样的图像内容。
- **少量有标签的猫狗图片**：这些图片量少，但已经标注了具体的类别（猫或狗）。

**预训练阶段**：

- **使用无标签数据**：您首先利用这些大量的无标签图片进行预训练。通过设计一些自监督任务（例如旋转图片、填补图片的缺失部分等），模型学习到一些图像的通用特征（如边缘、纹理、形状等）。
- **特征的普适性**：虽然这些图片不一定是猫狗的图片，但它们的特征（如边缘、纹理等）是所有图片的共性，模型通过学习这些共性特征，为后续任务打下基础。

**下游任务阶段**：

- **应用于猫狗分类**：然后，您将已经在无标签数据上预训练好的模型（或编码器）应用到有标签的猫狗分类任务上。
- **微调模型**：在有标签的猫狗数据上进行微调，使模型能够更好地适应和区分猫和狗的特征。

**最终效果**：

- **快速适应**：由于模型已经在预训练阶段学到了很多有用的图像特征，所以它可以在少量的猫狗有标签数据上快速调整和优化，从而在下游任务中达到良好的分类效果。

![image-20240809220537343](D:\zjPhD\notes\notes\AI\cs231n\图片\41.png)

![image-20240809220614560](D:\zjPhD\notes\notes\AI\cs231n\图片\42.png)

# 一些常见的预训练任务

**图像补全（Image Completion）**：

- 任务：给定一部分被遮挡的图片，让模型预测和生成被遮挡的部分。
- 目的：通过让模型学会补全图片，模型将学习到如何理解图片的整体结构和内容，从而获得更好的图像特征表示。

**旋转预测（Rotation Prediction）**：

- 任务：将图片旋转一个随机角度（如90度、180度、270度），然后让模型预测图片被旋转的角度。
- 目的：这个任务使模型学会识别图片中的方向和结构性特征，从而增强对图像内容的理解。

**拼图任务（“Jigsaw Puzzle”）**：

- 任务：将一张图片切割成多个小块，然后打乱它们的顺序。模型的任务是重新排列这些块，恢复原图。
- 目的：通过这个任务，模型学会了图片局部和全局特征之间的关系，从而更好地捕捉到图像的整体内容。

**图像上色（Colorization）**：

- 任务：将一张灰度图像转换为彩色图像。即输入为灰度图像，输出为彩色图像。
- 目的：这个任务帮助模型学习颜色与物体和场景之间的关系，从而丰富图像特征的表示。

# 如何评估自监督学习方法

**预训练任务表现（Pretext Task Performance）**

- **目的**：评估模型在无标签数据上的预训练任务中表现如何。
- **解释**：这是检查模型在自监督学习过程中学到的内容是否能够有效地完成预训练任务。例如，如果预训练任务是预测图片旋转角度，那么就看模型在这个任务上的表现如何。

**表示质量（Representation Quality）**

- **目的**：评估模型学习到的特征表示的质量。
- **解释**：有几种方法可以评估表示质量：
  - **线性评估协议（Linear Evaluation Protocol）**：在学习到的特征表示上训练一个线性分类器，看看在下游任务中的表现如何。
  - **聚类（Clustering）**：通过聚类的性能来衡量特征表示的质量，比如看模型能否将相似的样本很好地聚集在一起。
  - **t-SNE**：通过t-SNE可视化技术来观察特征表示的可分离性，检查不同类别是否能够清晰地分开。

**鲁棒性和泛化能力（Robustness and Generalization）**

- **目的**：测试模型在不同数据集上的泛化能力以及对变化的鲁棒性。
- **解释**：这部分评估模型能否在与训练数据集不同的数据集上依然表现良好，以及在数据分布或数据扰动下能否保持稳定的表现。

**计算效率（Computational Efficiency）**

- **目的**：评估方法在训练时间和资源需求方面的效率。
- **解释**：考察自监督学习方法的计算效率，尤其是考虑到预训练阶段可能需要处理大量无标签数据时，评估模型在训练过程中的时间消耗和资源需求。

**迁移学习和下游任务表现（Transfer Learning and Downstream Task Performance）**

- **目的**：通过将学到的特征表示迁移到下游有监督任务中来评估它们的效用。
- **解释**：这是最终评估自监督学习方法有效性的重要步骤，检查模型在完成下游任务（如分类、回归等）时表现如何。如果预训练阶段学到的特征在下游任务中表现优秀，则说明自监督学习方法是有效的。

![image-20240810021026370](D:\zjPhD\notes\notes\AI\cs231n\图片\43.png)

展示了如何评估自监督学习方法的有效性：

- **第一步**：在大量无标签数据上进行自监督学习，学习到通用的特征表示。
- **第二步**：使用少量有标签数据在目标任务上进行有监督学习，通过微调和浅层网络使模型适应具体任务。
- **第三步**：通过目标任务上的表现来评估模型的性能。

一个模型如果具备视觉上的常识，即了解物体在正常状态下的应该是什么样子，他就能够识别出物体的正确旋转角度。

如果一个模型能够理解物体在正常情况下的外观（例如，鸟类是直立的，青蛙通常趴在地上，那么它能够识别这些物体的旋转）